# ATLAS N  
Формальные основания экспериментальной картографии сложных параметризованных систем

⚠️ Статус  
Данный текст — проект исследовательской записки (idea vault) и каркас будущей спецификации. Он не является продуктовой документацией, стандартом или руководством к действию.

Эмпирических результатов пока нет; все определения, метрики и правила ниже являются рабочими гипотезами и могут быть пересмотрены. Пока что это каркас, который я стараюсь сделать максимально воспроизводимым с самого начала, чтобы потом не чинить методологию задним числом. А то потом опять придётся переписывать всё с нуля, как обычно бывает. Хочу, чтобы через год-полтора, когда данные уже будут, не пришлось говорить: «ой, а мы же контекст не фиксировали полностью».

ATLAS N задуман как живой исследовательский проект; по мере появления первых данных многие формулировки (особенно в разделах 4–5) будут пересмотрены после первых сотен (ориентировочно 500–1000) экспериментов.  
В общем, цель простая: не обманывать самих себя красивыми формулами, пока нет хотя бы тысячи строчек в логе.

### Аннотация  
ATLAS N — методология и проект исполняемой системы для систематического исследования пространств конфигураций сложных параметризованных систем в условиях частичной наблюдаемости и динамического контекста. В отличие от утилитарных подходов, ориентированных на поиск отдельных «рабочих» конфигураций, ATLAS N ставит задачу построения воспроизводимой карты знания о поведении системы как функции конфигурации и контекста.

В качестве модельного домена используется VPN-система, обладающая высокой размерностью, нестабильностью и контекстной чувствительностью. В рамках ATLAS N предлагаются:

- формальная модель знания для частично наблюдаемых систем  
- операционные инварианты процесса, оформленные как исполнимые правила  
- структурный язык описания пространства конфигураций (кластеры, границы, хаотические области)  
- постановка задачи оптимального информационного исследования  
- минимальная формальная спецификация базовых safety-свойств процесса накопления данных  
- канон MVRS как исполнимый контракт между методологией и реализацией  

Текущая версия описывает целевую форму системы и минимальный набор проверок, которые можно автоматизировать до появления эмпирики. Разделы 4–5 задают язык карты и планирования экспериментов; они станут практически осмысленными только после накопления минимального объёма наблюдений.

### 1. Проблема: исследование сложных параметризованных систем  
#### 1.1. Почему VPN — подходящая модельная система  
VPN-системы являются удобным примером сложных параметризованных систем по следующим причинам:

- высокая размерность пространства конфигураций (протоколы, криптография, транспорт, параметры, эндпоинты, маршрутизация)  
- динамичность среды (изменение сетевых условий, фильтрации, DPI, инфраструктуры)  
- сильная контекстная зависимость (время, география, путь в сети, клиентский стек, состояние ОС)  
- частичная наблюдаемость: наблюдаемы только вход (конфигурация, контекст) и выход (исход), но не внутренние механизмы поведения системы  

Эти свойства делают VPN-домен показательным примером класса систем, где наивные методы поиска решений систематически терпят неудачу.

#### 1.2. Ограничения традиционного подхода  
Эвристический поиск «рабочих» конфигураций и агрегированные рейтинги обладают рядом фундаментальных недостатков:

- знание непереносимо — каждый исследователь начинает заново  
- воспроизводимость низкая — успех в одном контексте не гарантирует успеха в другом  
- отрицательные результаты теряются и не накапливаются  
- отсутствует объяснительная сила: нет ответа на вопрос «почему»  

В результате система остаётся эмпирически непрозрачной, а накопленный опыт не конвертируется в устойчивое знание.

#### 1.3. Картография вместо поиска  
ATLAS N заменяет задачу поиска решений задачей картографирования поведения системы. Базовая единица наблюдения — тройка:

$$ (c, k, o), \quad o \in O = \{\text{SUCCESS}, \text{FAILURE}, \text{ERROR}\}, $$

где \(c\) — конфигурация, \(k\) — контекст выполнения, \(o\) — наблюдаемый исход.

Совокупность таких наблюдений формирует карту, позволяющую:

- выявлять структурные элементы (кластеры, границы, аномалии)  
- прогнозировать поведение в неисследованных областях  
- различать устойчивые закономерности и контекстные эффекты  
- отслеживать эволюцию ландшафта доступности во времени  

Рабочая гипотеза ATLAS N: даже в нестабильных доменах могут проявляться устойчивые структуры в выбранной дискретизации \(\Pi\) и при фиксированном профиле измерений (MethodologyRef). До появления данных гипотеза считается неподтверждённой; канон MVRS гарантирует качество протокола наблюдений, но не гарантирует наличие структуры «в мире».

Первичный критерий опровержения: при росте числа повторов \(N(c,k)\) распределения исходов не демонстрируют сходимости по выбранной метрике стабильности даже в сопоставимых контекстах.

### 2. Формальная модель знания  
#### 2.1. Базовые определения  
Пусть:

- \(C\) — пространство конфигураций (конечное или счётное)  
- \(K\) — пространство контекстов выполнения  
- \(O = \{\text{SUCCESS}, \text{FAILURE}, \text{ERROR}\}\) — множество наблюдаемых исходов  
- \(f : C \times K \to O\) — истинная, но неизвестная функция поведения системы  

Наблюдаемые данные к моменту времени \(t\):

$$ D_t = \{(c_1, k_1, o_1), \ldots, (c_n, k_n, o_n)\}, $$

где каждое наблюдение представлено как неизменяемый ExperimentRecord, содержащий полный ContextSnapshot.

Обозначим покрытое множество:

$$ S_t \subseteq C \times K, $$

состоящее из всех пар \((c, k)\), для которых существует хотя бы одно наблюдение.

#### 2.2. Неопределённость на покрытии и покрытие пространства  
Здесь я предлагаю на старте оценивать вероятности исходов для каждой пары \((c,k)\) с использованием псевдосчётов Дирихле (\(\alpha = 1\)):

$$ \hat{P}(o \mid c,k) = \frac{N(c,k,o) + 1}{N(c,k) + |O|}. $$

Суммарная остаточная неопределённость на покрытии:

$$ H_{\text{refine}}(t) = -\sum_{(c,k) \in S_t} \sum_{o \in O} \hat{P}(o \mid c,k) \log_2 \hat{P}(o \mid c,k). $$

Важно: как суммарная величина \(H_{\text{refine}}(t)\) может расти при расширении покрытия \(S_t\), что само по себе не является деградацией качества знания; это отражает увеличение объёма описываемой области. Для сравнения состояний при разном покрытии используется нормированная форма \(H_{\text{refine}}(t) / |S_t|\), интерпретируемая как средняя неопределённость на точку покрытия.

Мера покрытия для конечного пространства:

$$ \text{Coverage}(t) = \frac{|S_t|}{|C \times K|}. $$

Для бесконечного или практически недостижимого пространства — приближение через версионированную дискретизацию \(\Pi\) (MethodologyRef):

$$ \text{Coverage}_{\Pi}(t) = \frac{|\Pi(S_t)|}{|\Pi(C \times K)|}. $$

Таким образом:

- \(H_{\text{refine}}(t) = 0\) соответствует полной определённости на покрытии  
- высокая Coverage при высоком \(H_{\text{refine}}\) означает поверхностное исследование  
- снижение \(H_{\text{refine}}\) без роста Coverage означает локальное уточнение  

Статус: \(H_{\text{refine}}\) предлагается как удобная сводная величина, но её корреляция с практической «ценностью карты» пока не валидирована. Если метрика окажется бесполезной — это тоже будет полезно понять; тогда мы её просто выкинем или заменим. Сравнения между состояниями с разной \(\Pi\) и разным профилем \(K\) допускаются только при равенстве MethodologyRef.

#### 2.3. Информационная ценность наблюдений  
Для \(p = P(\text{SUCCESS} \mid c,k)\) вводится локальная мера неожиданности (surprisal):

$$ I(\text{success}) = -\log_2 p, \quad I(\text{failure}) = -\log_2 (1-p). $$

Следствия:

- при \(p < 0.5\) неудача информативнее успеха  
- максимальная информативность достигается в области \(p \approx 0.5\)  

Эта мера используется как локальная эвристика. Ожидаемый информационный выигрыш задаётся через ожидаемое изменение \(H_{\text{refine}}\) (см. раздел 6).

### 3. Фазы процесса: Phase I и Phase II  
В ATLAS N процесс исследования разделён на две фазы: Phase I и Phase II. Это разные процессы с разными задачами.

**Phase I** — фаза регистрации наблюдений. На этой фазе система:

- принимает конфигурацию и контекст  
- выполняет эксперимент  
- фиксирует наблюдаемый исход  
- сохраняет полный снимок контекста и артефакты воспроизводимости  

Phase I не выполняет анализа и не использует результаты Phase II. Её результат — журнал наблюдений, пригодный для повторного чтения и сравнения во времени и между запусками.

**Phase II** — фаза анализа и интерпретации. Это отдельный процесс, который работает только с данными, зафиксированными на Phase I. На Phase II выполняются:

- агрегация наблюдений  
- расчёт метрик  
- построение структур карты  
- формирование интерпретаций и гипотез  

Phase II не участвует в выполнении экспериментов и не влияет на процесс регистрации данных.

Связь между фазами односторонняя: Phase I → Phase II. Обратная зависимость между фазами не допускается; Phase I не использует результаты Phase II ни напрямую, ни косвенно.

Наличие Phase II не является необходимым условием для выполнения Phase I: эксперименты могут выполняться и накапливаться независимо от того, запущен ли анализ.

### 4. Инварианты как нормы процесса и исполнимые правила  
Здесь «инварианты» — это требования к протоколу эксперимента и хранилищу (process invariants). Они не утверждают ничего о доменной причинности VPN; они утверждают, что наблюдения пригодны для сравнения во времени и между запусками.

#### 4.1. Монотонность знания (I-02.01)  
Требование:

$$ D_{t+1} \supseteq D_t. $$

Удаление или модификация наблюдений разрушает сходимость метрик знания и делает сравнение состояний системы некорректным.

Правило I-02.01 (нестираемость):  
ExperimentRecord неизменяем. Исправления допускаются только через CorrectionRecord, ссылающийся на оригинал. Архитектура — строго append-only.  
Severity: CATASTROPHIC.  
Наблюдаемые индикаторы: отсутствие операций UPDATE и DELETE; монотонный рост журнала; корректные ссылки исправлений.  
Формальная спецификация и машинные проверки правил — см. канон MVRS (раздел 9).

#### 4.2. Разделение фаз (I-06.01)  
Генерация наблюдений (Phase I) не должна зависеть от интерпретации и анализа данных (Phase II).

Правило I-06.01:  
Phase I и Phase II реализованы как логически и физически раздельные процессы и хранилища. Phase I не использует результаты Phase II.  
Severity: CATASTROPHIC.  
Индикаторы: раздельные БД и артефакты; отсутствие обратных зависимостей; воспроизводимость Phase I при отключённой Phase II.

#### 4.3. Полнота контекста (I-01.01)  
Без полного контекста наблюдения могут создавать кажущееся противоречие: одинаковая конфигурация ведёт себя «по-разному» в якобы одинаковых условиях.

Правило I-01.01:  
Каждый ExperimentRecord обязан содержать полный ContextSnapshot, валидируемый версионированной схемой.  
Severity: CATASTROPHIC.

### 5. Структура пространства конфигураций  
#### 5.1. Метрика  
Здесь я предлагаю на старте использовать метрику на пространстве \(C \times K\):

$$ d((c_1, k_1), (c_2, k_2)) = \alpha \cdot d_C(c_1, c_2) + \beta \cdot d_K(k_1, k_2), $$

где \(d_C\) и \(d_K\) задаются проектом (например, Хэммингово расстояние по параметрам).

#### 5.2. Операциональные структуры  
Описанные структуры (кластеры, границы, хаотические области) являются операциональными: они определяются выбранной метрикой \(d\), радиусом \(r\) и порогами \(\tau, \varepsilon\), и потому отражают модель карты, а не «объективную географию» системы.

Фиксируем радиус \(r\) и строим граф соседства \(G_r\) на покрытии \(S_t\): вершины — пары \((c,k) \in S_t\), ребро проводится, если \(d \le r\).

- устойчивый кластер: связная компонента в \(G_r\), где доля доминирующего исхода \(\ge \tau\)  
- граница: для каждой точки в компоненте в её \(r\)-окрестности встречаются как минимум два исхода с долей \(\ge \varepsilon\)  
- хаотическая область: высокая чувствительность — близкие точки по \(d\) демонстрируют существенно различающиеся распределения исходов  

Параметры \(r, \tau, \varepsilon\) являются ключевыми гиперпараметрами методологии: их выбор фиксируется в MethodologyRef и определяет гранулярность карты.

### 6. Оптимальное информационное исследование  
#### 6.1. Два типа прогресса  
- уточнение на покрытии (снижение \(H_{\text{refine}}(t)\))  
- расширение покрытия (рост Coverage по выбранной дискретизации \(\Pi\))  

#### 6.2. Ожидаемый информационный выигрыш  
Для уточнения:

$$ IG_{\text{refine}}(c,k) = H_{\text{refine}}(t) - \mathbb{E}\left[ H_{\text{refine}}(t+1) \mid (c,k) \right]. $$

#### 6.3. Планирование экспериментов  
В дискретизованном пространстве используется эвристика:

$$ (c_{\text{next}}, k_{\text{next}}) = \arg\max \left[ IG_{\text{estimate}}(c,k) + \gamma \sqrt{\frac{\log t}{N(c,k)}} \right], $$

где \(\gamma\) — коэффициент баланса исследования. Эвристика не претендует на строгие гарантии и используется как практический ориентир.

Практическая оговорка: на первых порах UCB-подобная эвристика почти наверняка будет отключена. Ранний дрейф контекста и нестабильность измерений могут сделать любые приоритеты бессмысленными; на старте важнее агрессивное покрытие и сбор базовой статистики шума, потому что если сразу начинать с «умного» планировщика, то через неделю всё равно вернёшься к рандому, проверено на других проектах.

До накопления минимального объёма данных планирование работает в режиме bootstrap: равномерная или стратифицированная выборка по \(\Pi\) и приоритет покрытия над уточнением. На старте я скорее всего буду запускать случайную стратифицированную выборку по текущей \(\Pi\), пока не наберётся хотя бы 50–100 повторов на кластер (ориентир, может поменяться после первых прогонов, как всегда). Выбор дискретизации \(\Pi\) и принцип выбора новых точек \((c,k)\) для расширения покрытия (вне \(S_t\)) является частью методологического профиля (MethodologyRef) и фиксируется как элемент воспроизводимости исследования.

### 7. Минимальная формальная верификация протокола накопления данных  
Верификация ограничивается процессом накопления данных, а не доменной логикой VPN. Объект верификации — свойства хранилища и протокола записи (append-only, ссылки на CorrectionRecord, неизменяемость, разделение фаз). Не объект — истинность гипотез о структуре пространства.

Моделируется:

- состояние как множество ExperimentRecord  
- единственный переход — добавление записи  
- невозможность удаления или изменения наблюдений  

Инвариант монотонности (append-only):

$$ D_{t+1} \supseteq D_t. $$

Следствие:

$$ |D_{t+1}| \geq |D_t|. $$

Не моделируются: сетевые эффекты, DPI, причинные механизмы. Ограничения фиксируются явно.

### 8. Практическая декомпозиция (VPN как пример)  
Типовая факторизация:

$$ C = \text{Protocols} \times \text{Ciphers} \times \text{Parameters} \times \text{Endpoints} \times \text{Transport}, $$  
$$ K = \text{NetworkProfile} \times \text{Time} \times \text{Geolocation} \times \text{ClientStack} \times \text{MethodologyRef}. $$

Phase I фиксирует контекст, выполняет эксперимент и записывает артефакты воспроизводимости.  
Phase II анализирует данные независимо.

### 9. Канон MVRS как исполнимый контракт  
SSOT: rules/canonical/mvrs.yaml.

В этой версии я фиксирую MVRS как набор правил, каждое из которых содержит:

- идентификатор  
- intent  
- формальную формулировку  
- машинную проверку  
- severity  
- типовой сценарий нарушения  

MVRS может иметь режимы строгости (draft или strict). В draft допускаются неполные контексты с явным флагом INCOMPLETE_CONTEXT и сниженной Severity; в strict любое нарушение трактуется как CATASTROPHIC. Пока нет эмпирики, strict — целевое состояние, но разработка может идти в draft, чтобы не блокировать сбор первых данных.

Нарушение любого правила означает, что система перестаёт соответствовать ATLAS N.

### 10. Ограничения  
- локальная гладкость может разрушаться пороговыми эффектами  
- пространство \(C \times K\) практически бесконечно  
- контекст наблюдаем не полностью  
- качество карты ограничено качеством фиксации контекста и выбранной дискретизацией  

### 11. Заключение  
ATLAS N формализует переход от поиска решений к накоплению карты знания. Его вклад заключается в:

- явной модели знания для частично наблюдаемых систем  
- формализации инвариантов протокола исследования  
- исполняемом каноне MVRS  
- переносимости подхода на другие домены (БД, компиляторы, облачные конфигурации, безопасность)  

### 11A. Открытые вопросы и инженерные TBD (до первых данных)  

#### Вопросы о приватности, безопасности, DPI, JA3 и маскировке трафика (самые параноидальные и самые смешные)

- Какие компоненты контекста \(K\) реально измеримы на практике без утечек приватности и секретов? Или всё равно через полгода кто-то найдёт мой домашний IP в логе и скажет «ну ты, конечно, конспиролог»?  
- Как фиксировать «географию или путь» без деанонимизации и без хранения сырых IP или endpoint-данных? А то опять будем объяснять, почему у нас в отчёте лежит чужой сервер, который уже трижды забанен.  
- **Как не слить в логах приватные ключи, сертификаты или хотя бы отпечатки серверов, если мы хотим сохранить артефакты для воспроизводимости?** Или проще сказать «ну мы же не храним, мы только хэшируем… ой, а хэш-то можно брутфорсить»?  
- **Как логировать трафик и ошибки без записи payload'ов, чтобы потом не оказалось, что мы случайно сохранили чей-то пароль или личное сообщение?** Потому что если сохраним — это уже не исследование, а уголовка, а если не сохраним — «а почему у тебя handshake не воспроизводится?».  
- **Как защитить сам репозиторий с логами Phase I от утечек, если мы хотим открыть его публично?** Или проще держать всё локально и потом говорить «да у меня данные есть, просто не показываю»?  
- **Как маскировать JA3-отпечаток нашего клиента, чтобы DPI не понял, что это не обычный Chrome, а «очень подозрительный бот, который тестирует 1000 конфигов в час»?** Или проще сразу сказать «ну мы же не параноики» и ждать, когда нас кинут в чёрный список?  
- **Как ротировать JA3 (TLS-расширения, порядок, ciphers) без потери воспроизводимости?** Или надеяться, что DPI не заметит, потому что «мы же не 100 тысяч запросов в секунду шлём», а потом через неделю всё равно переписывать систему?  
- **Как отличить FAILURE по JA3-блокировке от обычного таймаута?** Или проще сказать «если handshake рвётся после ClientHello — значит JA3 нас сдал, и всё, сворачиваемся»?  
- **Как тестировать JA3-маскировку (uTLS, random ciphers, fake extensions) без риска, что DPI нас заметит и начнёт резать весь диапазон IP?** Потому что если будем гонять тысячи вариантов — нас точно вычислят за день, и проект превратится в «мы помогли РКН научиться резать uTLS».  
- **Что делать, если JA3 начнёт меняться сам по себе (разные ОС, библиотеки, рантаймы)?** Это уже «дрейф JA3» или «автор опять обновил Python и забыл»? Как фиксировать, чтобы потом не говорить «а почему у тебя JA3 не воспроизводится»?  
- **Как не превратить Phase I в «бесплатный генератор сигнатур для DPI»?** Потому что если будем пробовать все комбинации — DPI научится резать именно наши паттерны, и мы станем соавторами собственной смерти.  
- **Как логировать признаки DPI-сканирования (аномальные RST, подменённые сертификаты, разрывы после ClientHello) без записи пакетов?** А то если запишем — уголовка, если не запишем — «а почему у тебя DPI не воспроизводится?».  
- **Как не попасть в ситуацию, когда наши попытки маскировки сами становятся сигнатурой?** Потому что если будем использовать uTLS + random padding + fake HTTP/2 — DPI через месяц научится резать именно это, и мы станем «отцами» новой блокировки.  
- **Как не превратить проект в «ещё один источник для тренировки DPI»?** Если через три месяца DPI научится резать наши JA3 и handshake'ы — это будет самая воспроизводимая помощь цензуре в истории, и нас точно не похвалят.

Инженерные (приземлённые) вопросы:

- Какой объём артефактов Phase I мы готовы хранить (10 МБ, 100 МБ, 1 ГБ на 1000 экспериментов)?  
- Нужна ли ротация ContextSnapshot или важнее простота?  
- Какой таймаут считать FAILURE?  
- Какой максимум времени на эксперимент?  
- Если железо перегреется или интернет отвалится — как это фиксировать, чтобы не говорить «ну это же не по-научному»?  

Эти вопросы — не список «что забыли», а места, где проект может либо научиться жить под DPI, либо тихо стать «ещё одним мёртвым репозиторием, который помог улучшить фильтрацию». Ответы появятся только после первых прогонов… если доживём.
